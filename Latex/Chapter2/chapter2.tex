% Activate the following line by filling in the right side. If for example the name of the root file is Main.tex, write
% "...root = Main.tex" if the chapter file is in the same directory, and "...root = ../Main.tex" if the chapter is in a subdirectory.

%!TEX root = 

\chapter{Structure}

A brief preface to the deluge of information about Lean which follows:
all of the information I used about how Lean works comes from the Lean 
resources \textit{Theorem Proving in Lean 4}\cite{TPiL} and 
\textit{Mathematics in Lean}\cite{MIL}, or from my synthesis of select
sections of the Lean library Mathlib, or from the experience
I have gathered working with Lean for the past year.

\section{Introduction to Lean and Logic}

Conventionally, Propositional Logic is taught with a few basic ideas:
A proposition is any statement which can be binarily assigned true or 
false, and every proposition must be either true or false. Next introduced 
are truth tables, and different means of combining propositions into 
larger propositions. We define the meaning of conjunction by appealing to 
a truth table, wherein \lean{P $\wedge$ Q} is true if and only if \lean{P} is true 
and \lean{Q} is true. Similar constructions define negation, disjunction, 
and implication. This proof-by-truth-table perspective is used when
first learning formal logic, but is swiftly discarded as one proceeds
further into mathematics. Already by the time students learn 
about the universal quantifier, the truth table is obsolete.
A conventional foundation for mathematics also uses sets as the 
fundamental building block, constructing the natural numbers and so 
forth from the axioms of Zermelo-Fraenkel set theory \cite{RealAnalysis}.

Lean, in contrast, builds its whole world, even its logic, from types. 
In Lean, every term has some Type, and true-or-false claims have the type 
\lean{Prop}, which is short for Propositions. Any given term \lean{P} with
type \lean{Prop} (denoted \lean{P : Prop}) is itself a type, and a term 
\lean{hp} of type \lean{P} (denoted \lean{hp : P}) is understood to be a 
proof of the proposition \lean{P}. Therefore any function which produces as its
output a term of type \lean{P} is a means by which \lean{P} can be proven. This gives 
us a vehicle by which we can conceive of implication! If there is a function
\lean{f} which takes as its argument some term \lean{hp} of type \lean{P} and returns
a term of type \lean{Q}, then \lean{f} is a term with type \lean{P $\to$ Q}. Provided that 
\lean{P} and \lean{Q} are terms with type \lean{Prop}, \lean{f} can be throught of as a proof
that \lean{P} implies \lean{Q}. This means of creating implication as a function from
one Proposition to another is known as the Curry-Howard Isomorphism, and
provides the basis for Lean as a proof assistant. 

The above mentioned introductions to logic are very different, so I needed
to make a choice with my code library: Do I adapt truth tables to
Lean and teach basic logic that way, or do I introduce basic logic through
introduction and elimination rules, as is infitting with how Lean itself 
is organized? I chose to follow the path tread by the structure of Lean itself,
especially because actual mathematical proof typically abandons truth tables
before long. Therefore my code library starts with a brief explanation of
propositions and proofs, where proofs are functions from one proposition to
another. I then introduce tactics and tactic states, the other main feature
of Lean. Tactics make proof-writing in Lean flow more smoothly and resemble 
proof-writing in Human language more than pure functional code. The tactic
state also represents to the reader/writer of Lean code the names of all
hypotheses already known (the function arguments and local variables) at any stage in the proof, as 
well as all the goals of the proofs (the type which the function should return).
Each new tactic employed updates the tactic state, so proving a theorem with
tactics amounts to writing tactics until all goals in the tactic state are resolved. 
I begin in \lean{C1\_LeanIntroduction$\backslash$S1\_LeanIntro} 
by equipping students with knowledge of just 3 basic tactics: 
\lean{intro}, \lean{apply}, and \lean{exact}.

The \lean{intro} tactic functions similarly to ``let" in a human language proof. 
In some proof about Natural numbers, one might write ``let n be a natural number."
Similarly, in Lean, one would write \lean{intro n}.
If the current goal in the tactic state is in the form \lean{P $\to$ Q}, then
\lean{intro hP} would update the tactic state so that there's a new hypothesis
\lean{hP : P} and a simplified goal \lean{$\vdash$ Q}. The chosen hypothesis name \lean{hP} is an arbitrary name here, whatever
sequence of alphanumeric characters follows the whitespace after \lean{intro} will
be the name assigned to the term introduced. 

The \lean{exact} tactic is used for finishing off a proof, and might be compared
to the phrase ``Because \_\_\_\_, the proof is complete." If the current goal is
\lean{$\vdash$ P} and there is some hypothesis \lean{hp : P}, 
then writing \lean{exact hp} would complete the proof.

The \lean{apply} tactic uses implications to change the goal. For example, 
given the goal \lean{$\vdash$ Q} and the hypothesis \lean{h : P $\to$ Q}, writing
\lean{apply h} would transform the tactic state such that the new goal
is \lean{$\vdash$ P}. Since it's known, thanks to \lean{h}, that \lean{P} implies \lean{Q}, 
then proving \lean{P} would suffice to prove \lean{Q}, and the \lean{apply}
tactic packages that logic into a single line.

Before we can move on to talk about logic besides implication, there's 
one more facet of implication to mention: Currying. Without yet defining
conjuction, we can still write types which have more than one input; If
I want to create a function with two inputs and only one output,
like addition on the Natural numbers (which are encoded by the 
type \lean{Nat : Type}), then my function ``\lean{add}'' will have type 
\lean{Nat $\to$ (Nat $\to$ Nat)}. This type can be conceptualized by
filling out the arguments of the multivariable function one at a time, so
\lean{add : Nat $\to$ (Nat $\to$ Nat)} is a function which takes some
\lean{Nat} like \lean{3 : Nat} to \lean{add 3 : Nat $\to$ Nat}. Here,
\lean{add 3} is the function from natural numbers to natural numbers
which adds three to its input. Then \lean{add 3 6 : Nat} is just the 
natural number which should be returned from 3+6, which reduces to 9.
This technique is called ``currying'', and is critical to understanding
the next section.

The code library then works through \lean{True}, \lean{False}, \lean{Not}, 
\lean{And}, \lean{Or}, and \lean{Iff}.
\begin{description}
    \item[\lean{True : Prop}] is the proposition which is always correct, 
    so we should always be able to produce a proof of \lean{True}. In Lean,
    the proof of \lean{True} is \lean{True.intro : True}. However, there's 
    not much one can do with a proof of \lean{True}.
    \item[\lean{False : Prop}] is the opposite, the proposition which is 
    never correct. Thus there is not introduction rule to prove \lean{False}, 
    but there is the principle ``ex falso'', the idea that anything can 
    follow from false premises. Lean is equipped with \lean{False.elim : False $\to$ P},
    where \lean{P : Prop} can be any proposition. 
    \item[\lean{Not : Prop $\to$ Prop}] is denoted $\lnot$, so for
    some \lean{P : Prop}, \lean{$\lnot$P} is also a \lean{Prop}. 
    \lean{Not P} is defined as \lean{P $\to$ False}.
    \item[\lean{And : Prop $\to$ Prop $\to$ Prop}] is denoted $\wedge$, so 
    for \lean{P Q : Prop}, then \lean{P $\wedge$ Q : Prop} is shorthand for 
    \lean{And P Q : Prop}. Unlike \lean{True} and \lean{False} which only 
    had one or the other, \lean{And} has both introduction and elimination
    rules: \begin{itemize}
        \item \lean{And.intro : P $\to$ Q $\to$ P $\wedge$ Q}, so for
        proofs \lean{hp : P} and \lean{hq : Q}, then 
        \lean{And.intro hp hq : P $\wedge$ Q}.
        \item \lean{And.left : P $\wedge$ Q $\to$ P}
        \item \lean{And.right : P $\wedge$ Q $\to$ Q} 
    \end{itemize}
    \item[\lean{Or : Prop $\to$ Prop $\to$ Prop}] is denoted $\vee$, so 
    for \lean{P Q : Prop}, then \lean{P $\vee$ Q : Prop} is shorthand for 
    \lean{Or P Q : Prop}. Similar to \lean{And}, \lean{Or} has three total 
    introduction and elimination rules: \begin{itemize}
        \item \lean{Or.inl : P $\to$ P $\vee$ Q},
        \item \lean{Or.inr : Q $\to$ P $\vee$ Q}, and
        \item \lean{Or.elim : P $\vee$ Q $\to$ (P $\to$ R) $\to$ (Q $\to$ R) $\to$ R}.
        This elimination rule follows from the principle that to prove any proposition 
        \lean{R} from a disjunction, one needs to prove that each part of
        the disjunction implies \lean{R} independently.
    \end{itemize}
    \item[\lean{Iff : Prop $\to$ Prop $\to$ Prop}] is denoted $\leftrightarrow$, so 
    for \lean{P Q : Prop}, then \lean{P $\leftrightarrow$ Q : Prop} is shorthand for 
    \lean{Iff P Q : Prop}. The logical connective \lean{Iff} represents 
    bi-implication, so \lean{P $\leftrightarrow$ Q} can be thought of as 
    \lean{(P $\to$ Q) $\wedge$ (Q $\to$ P)}, and is codified by the introduction
    and elimination rules: \begin{itemize}
        \item \lean{Iff.intro : (P $\to$ Q) $\to$ (Q $\to$ P) $\to$ P $\leftrightarrow$ Q}, so for
        proofs \lean{hp : P} and \lean{hq : Q}, then 
        \lean{Iff.intro hp hq : P $\leftrightarrow$ Q}.
        \item \lean{Iff.mp : P $\leftrightarrow$ Q $\to$ P $\to$ Q}
        \item \lean{Iff.mpr : P $\leftrightarrow$ Q $\to$ Q $\to$ P}
    \end{itemize}

\end{description}


\subsection{Dependent Types and Qualifiers}

Lean implements ``Dependent Type Theory," which allows for the quantifiers
$\forall$ and $\exists$ to be represented in Lean. If $\alpha$ is some
type and a predicate \lean{p} has type \lean{$\alpha\;\to$ Prop}, then 
\begin{itemize}
    \item \lean{$\forall$ x : $\alpha$, p x} is the proposition that every 
    term of type $\alpha$ satisifes \lean{p}, and
    \item \lean{$\exists$ x : $\alpha$, p x} is the proposition that
    at least one term of type $\alpha$ satisfies \lean{p}.
\end{itemize}
$\forall$ is a dependent function, so not just the output, 
but \textbf{the type of the output} depends on the input of the function; 
a term of type \lean{$\exists$ x : $\alpha$, p x} is a function from
a term \lean{x} of type $\alpha$ to a proof of \lean{p x}. In Lean,
\lean{Exists} has type \lean{($\alpha\;\to$ Prop) $\to$ Prop}. The introduction
rule \lean{Exists.intro} has dependent type, so for any \lean{x : $\alpha$},
then \lean{Exists.intro x} has type \lean{p x $\to$ Exists p}. The elimination
rule \lean{Exists.elim} has type 
\lean{($\exists$ x, p x) $\to$ ($\forall$ a : $\alpha$, p a $\to$ b) $\to$ b}, essentially
saying that if \lean{b} is implied by any term which satisfies \lean{p}, then 
\lean{b} is implied by the existence of a term which satisfies \lean{p}.

\subsection{Are ``to be" and ``not to be" the only options?}

Using the the Curry-Howard Isomorphism and defining logical connectives
with introduction and elimination rules creates a system of logic which
is almost as expressive as classical logic, but it has a few limitations.
It's not possible to prove \lean{P $\vee\lnot$ P} for an arbitrary proposition \lean{P}
with constructive logic, the logic we have been using in Lean thus far.
Lean introduces three axioms in order to use the law of the
excluded middle: propositional extensionality, functional
extensionality, and an axiom of choice. Propositional extensionality is the
axiom that equivalent propositions are entirely equal, functional extensionality
is an axiom stating any two functions which return the same outputs for any
given input are entirely equal, and the choice axiom is a function of which produce
any term of an arbitrary type $\alpha$ given that $\alpha$ is a nonempty
type. Then using Diaconescu's theorem, it's possible to show that for any
proposition \lean{P}, either \lean{P} or \lean{$\lnot$P} is true. 

My code library doesn't dwell very long on the differences between 
constructive and classical logic, nor does it discuss the measures
taken by the Lean library to extend its expressive capabilities to 
cover classical logic. The library is geared towards an audience of 
undergradute mathematics majors, so most of the time is spent developing
their understanding of classical logic.

\section{Set Theory}

The structure of the Set Theory chapter of my code library is modeled after 
\textit{Topology} by Munkres \cite{Munkres} and 
\textit{An Introduction to Proof through Real Analysis} 
by Madden and Aubrey \cite{RealAnalysis}, along with
some influence from the undergraduate course I took at the University of Arizona
in Formal Proof-Writing in Fall 2021, Math 323. 
The Set Theory chapter \lean{C2\_SetTheory} begins with a discussion of basic
set theory, then has sections for Relations and Induction. 
Induction is introduced here rather than in the opening logic section of the 
library because it requires more type theory to understand how induction is
implemented in Lean. As students work through \lean{C2\_SetTheory},
they will also be learning bits and pieces of type theory and how type theory
is used in Lean. 

\subsection{Fundamentals of Set Theory}

The first section of the Set Theory chapter, \lean{S1\_Basics} is 
a speedy introduction to Set Theory and a referral to Chapter 4 of
MIL. Sets in Lean are restricted to only contain elements of the 
same type, so \lean{Set Nat} is the type of all sets which contain
only natural number elements. Then each individual set \lean{S : Set X}
is a collection of terms of type \lean{X}, which can also be represented
by a predicate \lean{p : X $\to$ Prop} by considering the collection
of terms which the predicate maps to \lean{True}. 
Thus a map \lean{p : X $\to$ Prop} corresponds to the set 
\lean{S : Set X} given by \lean{x : X | p x} (the notation Lean uses for 
a set over terms of type X which satisfy some property, in this case \lean{p}). 
And given a set \lean{S : Set X}, the corresponding
predicate is a map \lean{p : X $\to$ Prop := $\lambda$ x : X $\mapsto$ x $\in$ S}. 
This ``\lean{$\lambda$ \_ : \_ $\mapsto$ \_}'' notation is used for 
functions in Lean, where the blank space before the colon is the input term, the
blank after the colon is the type of the input term, and the blank after the
map symbol is the term outputted by the function. Thus the previous expression, 
\lean{p : X $\to$ Prop := $\lambda$ x : X $\mapsto$ x $\in$ S}, can be read 
``\lean{p} is the function of type \lean{X $\to$ Prop} which maps a term
\lean{x} of type \lean{X} to the proposition that \lean{x} is an element of \lean{S}.''
Since sets are defined in terms of types, there is also a set which contains 
all terms of the given type, which Lean denotes \lean{Set.univ} (This set
corresponds to the predicate which is always true). Using \lean{Set.univ},
one can also think of the predicate-set correspondence as
that between indicator function and the sets they indicate.

After providing readers with enough set theory background to go read 
MIL chapter 4, my code library provides several illustrative exercises for
students to complete, some of which are adapted from MIL and some of which I 
created. One significant benefit of using Lean to learn mathematics is that
definitions can be accessed instantly, so although MIL doesn't define 
surjectivity or injectivity, students can jump to their definitions in Lean.
Two of the problems which I wrote explicitly require proving that a function is
injective or surjective, and students can decompose the terms using the
tactic \lean{dsimp[Surjective]} or \lean{dsimp[Injective]}, which unfold
the corresponding definitions.

\lean{S1\_Basics} also covers Cartesian products and arbitrary unions, since
both will be critical for the topology chapter to come.

\subsection{Relations}

Relations are implemented in Lean as maps \lean{r : X $\to$ X $\to$ Prop}. The 
main relations discussed in \lean{S2\_Relations} are order and equivalence relations,
beginning with an introduction to bundling in Lean. Many objects in 
mathematics are characterized not just by the sets or functions themselves,
but also by the properties they satisfy. For example, an equivalence relation
is not just any relation on a type, but a relation which is also reflexive, 
symmetric, and transitive. Thus the object of an equivalence relation is really
a quadruple: the relation itself and 3 properties of that relation. Lean accomplishes
this bundling of several types into a single type with structures and typeclasses.
A structure in Lean is a type with a constructor which has all the fields
as arguments, and elimination functions which extract the individual fields.
\begin{lstlisting}
    structure <name> <parameters> <parent-structures> where
    <constructor> :: <fields>
\end{lstlisting}
For example, consider how the \lean{Equivalence} relation is expressed in Mathlib:
\begin{lstlisting}
    structure Equivalence {$\alpha$ : Type} (r : $\alpha\to\alpha\to$ Prop) : Prop where
    refl  : $\forall$ x, r x x
    symm  : $\forall$ {x y}, r x y $\to$ r y x
    trans : $\forall$ {x y z}, r x y $\to$ r y z $\to$ r x z
\end{lstlisting}
Thus the structure \lean{Equivalence} is a bundle of 3 predicates on a given
relation \lean{r}: reflexivity, symmetry, and transitivity.

Lean also has a more sophisticated system of \textbf{typeclasses}, which are
structures around which Lean has automation infrastructure. Typeclasses use 
almost the same syntax as structures, aside from the keyword \lean{class} in
place of \lean{structure}. The facet of typeclasses explained in the relations
section of the code library is \textit{typeclass inference}, which is the
mechanism Lean uses to infer instances of typeclasses without the programmer
explicitly providing the instances. Lean keeps track of the most recent scoped 
definition of each particular instance, so instances don't have to be described
with specific variable names to be used. 

\lean{S2\_Relations} investigates two main types of relations: 
\textbf{order relations} like preorders, partial orders, well-ordering, 
and linear orders; and \textbf{equivalence relations}. Although there is 
plenty of mathematics to be done with other relations, the aim of the code library is to
provide students with a sufficient mathematical foundation to begin exploring topology.
The order topology and the quotient topology are essential to the study of basic topology, 
so I describe only the requisite information about relations for those studies. Since the order 
topology relies on intervals and rays in a linear order, the code library explores the orders
which are weaker than linear ordering, but sufficient for intervals and suprema. Similarly, 
the quotient topology requires a definition of a quotient, so the code library introduces equivalence
relations and builds up to how quotients are defined in Lean.

The subsection on order relations introduces readers to the strict order, then preorders
and partial orders. Lean defines the set of upper and lower bounds of a set using only 
the preorder, but I chose to work with the confines of a partial order so that the 
bounded sets have a unique supremum and infimum. Then I introduce readers to the lexicographic
order, which will be useful later in topology. The next file on order relations, \lean{P3\_intervals.lean}, delves into 
open and closed intervals and rays. Lean defines 8 different intervals (which also include rays) : 
\lean{Ioo}, \lean{Ioc}, \lean{Ioi}, \lean{Ico}, \lean{Icc}, \lean{Ici}, \lean{Iio}, and \lean{Iic}.
The 3-letter names can be thought of as acronyms where the first word is ``interval", and the 
second and third words are from the set {``open", ``closed", ``infinite"}. The second word of the 
acronym describes the lower bound of the interval (or ray) and the third word describes the 
upper bound. The bound is a strict inequality, a non-strict inequality, or nonexistent for
``open," ``closed," and ``infinite" respectively. This is why there are only 8 intervals described, 
as the interval which has no upper or lower bound is just the entire set. The interval file then
introduces the reader to immediate successors and predecessors defined in terms of intervals.

The final subsection is dedicated to the equivalence relation, and is split into two files: 
\lean{P4\_equiv.lean} explaining the equivalence relation and
\lean{P5\_quotient.lean} explaining the quotient construction.
Lean has a structure \lean{Equivalence} which was shown above, and the code library
introduces the reader to that structure first, showing an example of a relation
which has all three properties: 
\begin{lstlisting}
    def parity (x y : $\mathbb{Z}$) : Prop := $\exists$ k, x - y = 2 * k
\end{lstlisting}
I then introduce readers to the typeclass \lean{Setoid}, which allows for the
use of the infix \lean{$\approx$} and will be needed later for quotients. 
(This notation allows one to write \lean{x $\approx$ y} rather than 
\lean{parity x y}, for example.) The remainder of the file shows students how 
equivalence classes are defined and describes how equivalence classes are
type partitions. Knowing now that equivalence classes subdivide a type, 
the next file smoothly introduces the \lean{Quotient} type, 
where the terms are equivalence classes.

Lean actually has two quotient types, \lean{Quot} and \lean{Quotient}, where the
latter is built atop the former. \lean{Quot} is a strange kind of quotient which
is built from \textbf{any} relation, so the relation need not be an equivalence.
The traditional quotient is built in Lean as 
\lean{Quotient : Setoid $\alpha$ $\to$ Type}, so a new \lean{Quotient} type can 
be created by providing an instance of \lean{Setoid $\alpha$} for some type 
$\alpha$. The file then explains how to use this new type and how the quotient
type relates to the equivalence relation on the base type, specifically by
leading readers through a (mostly) worked example, the integers modulo 3.
I first describe a relation 
\lean{eqv (a b : $\mathbb{Z}$) : Prop := $\exists$ k, a-b = 3*k}, then
actually \textbf{prove} that \lean{eqv} is an equivalence relation. From there,
I construct an instance \lean{ZSetoid : Setoid $\mathbb{Z}$} (which is the integers
$\mathbb{Z}$ with a defined relation \lean{eqv}) and define the quotient
type \lean{Zmod3 := Quotient ZSetoid}, which consists of equivalence clasees. 
Since the terms of \lean{Zmod3} are equivalence classes of integers, 
Lean should provide a means of constructing a term explicitly by providing 
an integer, and Leans does this with the function
\lean{Quotient.mk (s : Setoid $\alpha$) (a : $\alpha$) : Quotient s}. 
Lean also supplies the following useful tools for interacting with the 
quotient type (and many more not listed here) :
\lean{Quotient.exists\_rep} posits that every term of the quotient type is
equal to the equivalence class of some term in the base type, 
\lean{Quotient.eq} states that two terms of the base type are \textit{equivalent} if
and only if the equivalence classes of those terms are \textit{equal} in the quotient type,
\lean{Quotient.lift} creates a function from the quotient type to any other type 
$\beta$ when provided some function from the base type to $\beta$ which
maps equivalent terms to the same output, and 
\lean{Quotient.lift\_mk} asserts that the function created from \lean{Quotient.lift}
maps the equivalence class to the same term that the original function would
map any representative of that equivalence class. With these theorems and some more, 
I guide readers through a proof that no perfect square of integers is two more than
any multiple of three.

\subsection{Induction}

Induction is a fundamental idea to Lean, since the language makes uses of
``inductive types." Proof by induction is also a critical idea for aspiring 
mathematicians to learn, as it's a frequently used proof technique. This
section, \lean{S3\_Induction}, first introduces readers to the mathematical notions
of strong and weak induction, then refers readers to \textit{Mathematics in Lean},
before returning with examples of induction and recursive definitions. Chapter 
5 Section 2 of MIL was indispensible to my understanding of inductive types in 
Lean, and is accessibly-written, enough for the undergraduate audience of this
code library, so I decided to send readers to that text directly rather than 
novicely rewriting the source material. 

The code library just builds atop the explanation in MIL, with more explicit 
examples and exercises to illustrate and practice the use of induction, 
inductive types, and recursive definitions. There is also a brief example
which proves the one missing step from a proof in the previous Quotient 
subsection.

\section{Topology}

The chapter \lean{C3\_Topology} is modeled more explicitly after 
\textit{Topology} by Munkres, but also includes
some influence from \textit{Topologies and Uniformities}
by James \cite{Uniform}, because 
the Lean library Mathlib uses \textit{Topologies and Uniformities}.
This final section introduces the idea of a topology, a topological basis,
and a handful of methods for constructing topologies. Unlike the primary 
resource for topology in Lean, Chapter 9 of \textit{Mathematics in Lean}, 
my library places minimal focus on filters and metric spaces. In fact, 
this code library bears no mention of metric spaces, which ought to
be remedied should the code library be expanded to cover more of topology.
The framework for topology in Mathlib uses filters extensively, which
are useful for codifying limits and continuity at a point, but I decided 
the filter approach to topology is less intuitive to an undergraduate student
than the basis approach for a first introduction.

\subsection{Topology and Bases}

\lean{P1\_topology.lean} introduces the formal definitions of a topology and a 
topological basis, then scaffolds a proof that the collection of arbitrary
unions of basis sets forms a topology. Just these two definitions require 
knowledge of much that was introduced in the previous set theory chapter:
structures, typeclasses, the axiom of choice, and arbitrary unions. Lean
uses a typeclass \lean{TopologicalSpace} to encode topologies, which can 
make comparing two or more topologies difficult, since instances usually
go unnamed in Mathlib. Thus to compare a set under two different topologies
requires explicitly providing variable names for each topology into whichever
theorems from Mathlib are used, otherwise Lean will infer the most recently 
defined instance of a suitable topology as an argument. Despite this mild 
annoyance, the typeclass framework is much more suitable in the common context 
where a set has a standard topology which would be irritating to explicitly 
derive at each stage. The choice to represent topologies with typeclasses also 
eases the use of hierarchies, so Hausdorff spaces and Metric spaces can 
simply be defined atop the \lean{TopologicalSpace} typeclass.

\lean{P2\_open.lean} expands upon the definition of ``open" and ``closed" sets, 
demonstrates that the finite union and arbitrary intersection of closed sets
remain closed, and introduces the definitions asnd some properties of the 
interior, closure, and boundary of a set.

The remaining three files, \lean{P3\_product.lean}, \lean{P4\_order.lean},
and \lean{P5\_subspace.lean} respectively cover the product, order, 
and subspace topologies as they are implemented in Lean. 